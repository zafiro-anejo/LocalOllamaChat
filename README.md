# MVP RAG-системы для анализа инвестиционных материалов

## Обзор решения
Представленное решение - MVP RAG-системы, предназначенной для обработки и анализа финансовых документов. 
Система автоматизирует процесс конвертации PDF-файлов в структурированный Markdown, выполняет семантическое разбиение текста с помощью LLM, строит гибридный индекс (векторный + BM25) в Qdrant и предоставляет веб-интерфейс для вопросов на естественном языке. 
Все компоненты работают локально (on-premise) в Docker-контейнерах, обеспечивая полную изоляцию и конфиденциальность данных. 
Благодаря использованию современных библиотек (Docling, llama-index, Qdrant) и локальному развёртыванию, система готова к дальнейшему расширению в соответствии с полным техническим заданием.

## Технические особенности реализации

### Инжест документов

**PDF → Markdown**: конвертация выполняется библиотекой Docling, которая поддерживает не только PDF, но и множество других форматов (DOCX, PPTX, XLSX, изображения).
В текущей версии реализована обработка PDF; благодаря использованию Docling, расширение на другие форматы может быть выполнено с минимальными изменениями.

**Извлечение структуры**: Docling сохраняет заголовки, таблицы, списки, а также может выполнять OCR для сканированных PDF (опция do_ocr). В текущей конфигурации OCR отключено для ускорения, но может быть включено при необходимости.

**Описания изображений**: для иллюстраций используется VLM-модель (qwen3-vl:2b), запущенная локально через Ollama. Описания внедряются в Markdown с тегами <image_description>.

**Метаданные**: имя исходного PDF сохраняется как имя файла .md. В дальнейшем метаданные (дата, отправитель, тема) могут быть извлечены из имени файла или дополнительного источника и сохранены в payload Qdrant.

### Парсинг

**Текстовые документы**: Docling извлекает заголовки (по уровням), таблицы (в виде Markdown), списки. Полученный Markdown содержит всю необходимую разметку.

**Финансовые модели (XLSX)**: хотя в MVP обрабатываются только PDF, Docling также умеет конвертировать Excel-файлы в Markdown, сохраняя таблицы, так что в текущую реализацию беспроблем добавить полноценный анализа формул (=NPV(), =IRR()) и связей между листами.

**Сканированные PDF**: Docling поддерживает OCR через Tesseract/RapidOCR; при включении соответствующей опции будет выполнен OCR с возможностью постобработки.

### Чанкинг

**Адаптивная стратегия**: используется двухэтапный подход с участием LLM (gemma3). Сначала текст разбивается по заголовкам, затем LLM анализирует эти куски и определяет границы смысловых разделов (ответ в формате split_after: X, Y).
Это позволяет получать семантически целостные чанки, оптимальные для поиска.

**Контекстуализация**: для каждого итогового чанка LLM генерирует краткое описание его места в документе (на русском языке). Это описание добавляется перед текстом чанка в тегах <chunk_context>, что улучшает понимание контекста при ретриве.
Метаданные чанков: текущая реализация не добавляет метаданные в узлы, но архитектура llama-index позволяет легко включить поля metadata (дата, сектор) в узлы и передать их в Qdrant для последующей фильтрации.

## Векторное хранилище и гибридный поиск

**Qdrant**: выбрана в качестве векторной БД благодаря поддержке фильтрации по метаданным и возможности гибридного поиска. Размерность векторов – 1024 (соответствует модели bge-m3). Коллекция создаётся автоматически.

**Гибридный поиск**: реализован через QueryFusionRetriever из llama-index, объединяющий результаты векторного ретривера (VectorIndexRetriever) и BM25-ретривера (BM25Retriever). BM25 работает на узлах, сохранённых в docstore (in-memory).
Для масштабирования на 100K+ документов возможен переход на полнотекстовый индекс Qdrant.

### RAG-оркестрация

**Ре-ранкинг**: используется LLMRerank (кастомная модель на базе LLM). Можно заменить на Cohere Rerank, если потребуется внешний сервис.

**Промпт-инжиниринг**: в текущей версии применяется стандартный синтезатор ответов ResponseMode.COMPACT. В систему заложена возможность замены на кастомный промпт, включающий финансовый шаблон, требование указывать источники и диапазон дат.

**Обработка числовых данных**: в MVP ответы возвращаются в исходном виде. Дальнейшее развитие может включать извлечение метрик, агрегацию и проверку согласованности с источниками.

### Инфраструктура и развёртывание

**Docker Compose**: все сервисы (Ollama, Qdrant, бэкенд, фронтенд) оркестрируются одним файлом.

**Загрузка моделей**: сервис ollama-pull автоматически загружает необходимые модели (bge-m3, gemma3, qwen3-vl:2b) при первом запуске.

**Тома**: данные Qdrant и модели Ollama сохраняются в томах, что позволяет перезапускать контейнеры без потери данных.

**On-premise**: все компоненты работают локально, без обращений к внешним API. Эмбеддинги, LLM, VLM – всё запущено в собственных контейнерах.

### Что реализовано в полном объёме

Конвертация PDF в структурированный Markdown с сохранением таблиц и изображений.

Динамический чанкинг с помощью LLM, адаптивный к смысловым разделам.

Гибридный поиск (векторный + BM25) через Qdrant.

Ре-ранкинг результатов.

Веб-интерфейс для вопросов и ответов.

Полностью локальная инфраструктура (on-premise).

## Инструкция по запуску проекта

### Способ 1. Локальный запуск (рекомендуется для разработки)

#### 1. Установка и запуск Ollama

Скачать и установить Ollama.

Загрузите необходимые модели:
```bash
ollama pull bge-m3
ollama pull gemma3
ollama pull qwen3-vl:2b
```
#### 2. Запуск бэкенда (FastAPI)
1. Перейти в директорию backend
2. Создать и активировать окружение
3. Установить зависимости
4. Поместить PDF-файлы, которые необходимо проиндексировать, в папку initial_files.
5. Запустить бэкенд:
```bash
uvicorn main:app --port 8000
```
При первом запуске все PDF из initial_files будут автоматически сконвертированы в Markdown (сохранятся в processed_files), затем будет построен индекс в Qdrant. Процесс может занять несколько минут в зависимости от количества и размера файлов.
#### 3. Запуск фронтенда (React)
1. Перейти в директорию frontend
2. Установить зависимости через npm install
3. Запустить фронтенд через npm start

### Способ 2. Запуск через Docker (контейнеризованная версия)

Этот способ подходит для развёртывания в изолированной среде или для демонстрации. Однако он не рекомендуется для активной разработки из-за длительного времени сборки образов и загрузки моделей при первом запуске.

В корневой директории проекта (где находится docker-compose.yml) выполнить:
```bash
docker-compose up --build
```
Процесс включает:

Сборку образов для бэкенда и фронтенда.

Запуск контейнеров: ollama, ollama-pull (загрузка моделей), qdrant, backend, frontend.

При первом запуске ollama-pull загрузит три модели, что может занять 10–20 минут. Вы увидите в логах сообщения pulling manifest, pulling layer и т.д.

После загрузки моделей и завершения конвертации PDF сервисы будут готовы к работе.

#### Доступ к приложению

**Frontend**: http://localhost:3000

**Backend**: http://localhost:8000

**Qdrant**: http://localhost:6333/dashboard
